# This file was auto-generated by Fern from our API Definition.

import typing

from humanloop import EvaluateeRequest, EvaluationsDatasetRequest, EvaluationsRequest
from humanloop.client import AsyncHumanloop, Humanloop

from .utilities import validate_response


async def test_create(client: Humanloop, async_client: AsyncHumanloop) -> None:
    expected_response: typing.Any = {
        "id": "id",
        "dataset": {
            "path": "path",
            "id": "id",
            "name": "name",
            "version_id": "version_id",
            "type": "dataset",
            "environments": [{"id": "id", "created_at": "2024-01-15T09:30:00Z", "name": "name", "tag": "default"}],
            "created_at": "2024-01-15T09:30:00Z",
            "updated_at": "2024-01-15T09:30:00Z",
            "created_by": {"id": "id", "email_address": "email_address", "full_name": "full_name"},
            "status": "uncommitted",
            "last_used_at": "2024-01-15T09:30:00Z",
            "commit_message": "commit_message",
            "datapoints_count": 1,
            "datapoints": [{"id": "id"}],
        },
        "evaluatees": [
            {
                "version": {
                    "path": "path",
                    "id": "id",
                    "name": "name",
                    "version_id": "version_id",
                    "created_at": "2024-01-15T09:30:00Z",
                    "updated_at": "2024-01-15T09:30:00Z",
                    "status": "uncommitted",
                    "last_used_at": "2024-01-15T09:30:00Z",
                    "model": "model",
                    "version_logs_count": 1,
                    "total_logs_count": 1,
                    "inputs": [{"name": "name"}],
                },
                "batch_id": "batch_id",
                "orchestrated": True,
            }
        ],
        "evaluators": [
            {
                "version": {
                    "path": "path",
                    "id": "id",
                    "name": "name",
                    "version_id": "version_id",
                    "created_at": "2024-01-15T09:30:00Z",
                    "updated_at": "2024-01-15T09:30:00Z",
                    "status": "uncommitted",
                    "last_used_at": "2024-01-15T09:30:00Z",
                    "spec": {"arguments_type": "target_free", "return_type": "boolean"},
                    "version_logs_count": 1,
                    "total_logs_count": 1,
                    "inputs": [{"name": "name"}],
                },
                "orchestrated": True,
            }
        ],
        "status": "pending",
        "created_at": "2024-01-15T09:30:00Z",
        "created_by": {"id": "id", "email_address": "email_address", "full_name": "full_name"},
        "updated_at": "2024-01-15T09:30:00Z",
    }
    expected_types: typing.Any = {
        "id": None,
        "dataset": {
            "path": None,
            "id": None,
            "name": None,
            "version_id": None,
            "type": None,
            "environments": ("list", {0: {"id": None, "created_at": "datetime", "name": None, "tag": None}}),
            "created_at": "datetime",
            "updated_at": "datetime",
            "created_by": {"id": None, "email_address": None, "full_name": None},
            "status": None,
            "last_used_at": "datetime",
            "commit_message": None,
            "datapoints_count": "integer",
            "datapoints": ("list", {0: {"id": None}}),
        },
        "evaluatees": (
            "list",
            {
                0: {
                    "version": {
                        "path": None,
                        "id": None,
                        "name": None,
                        "version_id": None,
                        "created_at": "datetime",
                        "updated_at": "datetime",
                        "status": None,
                        "last_used_at": "datetime",
                        "model": None,
                        "version_logs_count": "integer",
                        "total_logs_count": "integer",
                        "inputs": ("list", {0: {"name": None}}),
                    },
                    "batch_id": None,
                    "orchestrated": None,
                }
            },
        ),
        "evaluators": (
            "list",
            {
                0: {
                    "version": {
                        "path": None,
                        "id": None,
                        "name": None,
                        "version_id": None,
                        "created_at": "datetime",
                        "updated_at": "datetime",
                        "status": None,
                        "last_used_at": "datetime",
                        "spec": {"arguments_type": None, "return_type": None},
                        "version_logs_count": "integer",
                        "total_logs_count": "integer",
                        "inputs": ("list", {0: {"name": None}}),
                    },
                    "orchestrated": None,
                }
            },
        ),
        "status": None,
        "created_at": "datetime",
        "created_by": {"id": None, "email_address": None, "full_name": None},
        "updated_at": "datetime",
    }
    response = client.evaluations.create(
        dataset=EvaluationsDatasetRequest(version_id="version_id"),
        evaluatees=[EvaluateeRequest(version_id="version_id")],
        evaluators=[EvaluationsRequest(version_id="version_id")],
    )
    validate_response(response, expected_response, expected_types)

    async_response = await async_client.evaluations.create(
        dataset=EvaluationsDatasetRequest(version_id="version_id"),
        evaluatees=[EvaluateeRequest(version_id="version_id")],
        evaluators=[EvaluationsRequest(version_id="version_id")],
    )
    validate_response(async_response, expected_response, expected_types)


async def test_get(client: Humanloop, async_client: AsyncHumanloop) -> None:
    expected_response: typing.Any = {
        "id": "id",
        "dataset": {
            "path": "path",
            "id": "id",
            "name": "name",
            "version_id": "version_id",
            "type": "dataset",
            "environments": [{"id": "id", "created_at": "2024-01-15T09:30:00Z", "name": "name", "tag": "default"}],
            "created_at": "2024-01-15T09:30:00Z",
            "updated_at": "2024-01-15T09:30:00Z",
            "created_by": {"id": "id", "email_address": "email_address", "full_name": "full_name"},
            "status": "uncommitted",
            "last_used_at": "2024-01-15T09:30:00Z",
            "commit_message": "commit_message",
            "datapoints_count": 1,
            "datapoints": [{"id": "id"}],
        },
        "evaluatees": [
            {
                "version": {
                    "path": "path",
                    "id": "id",
                    "name": "name",
                    "version_id": "version_id",
                    "created_at": "2024-01-15T09:30:00Z",
                    "updated_at": "2024-01-15T09:30:00Z",
                    "status": "uncommitted",
                    "last_used_at": "2024-01-15T09:30:00Z",
                    "model": "model",
                    "version_logs_count": 1,
                    "total_logs_count": 1,
                    "inputs": [{"name": "name"}],
                },
                "batch_id": "batch_id",
                "orchestrated": True,
            }
        ],
        "evaluators": [
            {
                "version": {
                    "path": "path",
                    "id": "id",
                    "name": "name",
                    "version_id": "version_id",
                    "created_at": "2024-01-15T09:30:00Z",
                    "updated_at": "2024-01-15T09:30:00Z",
                    "status": "uncommitted",
                    "last_used_at": "2024-01-15T09:30:00Z",
                    "spec": {"arguments_type": "target_free", "return_type": "boolean"},
                    "version_logs_count": 1,
                    "total_logs_count": 1,
                    "inputs": [{"name": "name"}],
                },
                "orchestrated": True,
            }
        ],
        "status": "pending",
        "created_at": "2024-01-15T09:30:00Z",
        "created_by": {"id": "id", "email_address": "email_address", "full_name": "full_name"},
        "updated_at": "2024-01-15T09:30:00Z",
    }
    expected_types: typing.Any = {
        "id": None,
        "dataset": {
            "path": None,
            "id": None,
            "name": None,
            "version_id": None,
            "type": None,
            "environments": ("list", {0: {"id": None, "created_at": "datetime", "name": None, "tag": None}}),
            "created_at": "datetime",
            "updated_at": "datetime",
            "created_by": {"id": None, "email_address": None, "full_name": None},
            "status": None,
            "last_used_at": "datetime",
            "commit_message": None,
            "datapoints_count": "integer",
            "datapoints": ("list", {0: {"id": None}}),
        },
        "evaluatees": (
            "list",
            {
                0: {
                    "version": {
                        "path": None,
                        "id": None,
                        "name": None,
                        "version_id": None,
                        "created_at": "datetime",
                        "updated_at": "datetime",
                        "status": None,
                        "last_used_at": "datetime",
                        "model": None,
                        "version_logs_count": "integer",
                        "total_logs_count": "integer",
                        "inputs": ("list", {0: {"name": None}}),
                    },
                    "batch_id": None,
                    "orchestrated": None,
                }
            },
        ),
        "evaluators": (
            "list",
            {
                0: {
                    "version": {
                        "path": None,
                        "id": None,
                        "name": None,
                        "version_id": None,
                        "created_at": "datetime",
                        "updated_at": "datetime",
                        "status": None,
                        "last_used_at": "datetime",
                        "spec": {"arguments_type": None, "return_type": None},
                        "version_logs_count": "integer",
                        "total_logs_count": "integer",
                        "inputs": ("list", {0: {"name": None}}),
                    },
                    "orchestrated": None,
                }
            },
        ),
        "status": None,
        "created_at": "datetime",
        "created_by": {"id": None, "email_address": None, "full_name": None},
        "updated_at": "datetime",
    }
    response = client.evaluations.get(id="id")
    validate_response(response, expected_response, expected_types)

    async_response = await async_client.evaluations.get(id="id")
    validate_response(async_response, expected_response, expected_types)


async def test_delete(client: Humanloop, async_client: AsyncHumanloop) -> None:
    # Type ignore to avoid mypy complaining about the function not being meant to return a value
    assert client.evaluations.delete(id="id") is None  # type: ignore[func-returns-value]

    assert await async_client.evaluations.delete(id="id") is None  # type: ignore[func-returns-value]


async def test_update(client: Humanloop, async_client: AsyncHumanloop) -> None:
    expected_response: typing.Any = {
        "id": "id",
        "dataset": {
            "path": "path",
            "id": "id",
            "name": "name",
            "version_id": "version_id",
            "type": "dataset",
            "environments": [{"id": "id", "created_at": "2024-01-15T09:30:00Z", "name": "name", "tag": "default"}],
            "created_at": "2024-01-15T09:30:00Z",
            "updated_at": "2024-01-15T09:30:00Z",
            "created_by": {"id": "id", "email_address": "email_address", "full_name": "full_name"},
            "status": "uncommitted",
            "last_used_at": "2024-01-15T09:30:00Z",
            "commit_message": "commit_message",
            "datapoints_count": 1,
            "datapoints": [{"id": "id"}],
        },
        "evaluatees": [
            {
                "version": {
                    "path": "path",
                    "id": "id",
                    "name": "name",
                    "version_id": "version_id",
                    "created_at": "2024-01-15T09:30:00Z",
                    "updated_at": "2024-01-15T09:30:00Z",
                    "status": "uncommitted",
                    "last_used_at": "2024-01-15T09:30:00Z",
                    "model": "model",
                    "version_logs_count": 1,
                    "total_logs_count": 1,
                    "inputs": [{"name": "name"}],
                },
                "batch_id": "batch_id",
                "orchestrated": True,
            }
        ],
        "evaluators": [
            {
                "version": {
                    "path": "path",
                    "id": "id",
                    "name": "name",
                    "version_id": "version_id",
                    "created_at": "2024-01-15T09:30:00Z",
                    "updated_at": "2024-01-15T09:30:00Z",
                    "status": "uncommitted",
                    "last_used_at": "2024-01-15T09:30:00Z",
                    "spec": {"arguments_type": "target_free", "return_type": "boolean"},
                    "version_logs_count": 1,
                    "total_logs_count": 1,
                    "inputs": [{"name": "name"}],
                },
                "orchestrated": True,
            }
        ],
        "status": "pending",
        "created_at": "2024-01-15T09:30:00Z",
        "created_by": {"id": "id", "email_address": "email_address", "full_name": "full_name"},
        "updated_at": "2024-01-15T09:30:00Z",
    }
    expected_types: typing.Any = {
        "id": None,
        "dataset": {
            "path": None,
            "id": None,
            "name": None,
            "version_id": None,
            "type": None,
            "environments": ("list", {0: {"id": None, "created_at": "datetime", "name": None, "tag": None}}),
            "created_at": "datetime",
            "updated_at": "datetime",
            "created_by": {"id": None, "email_address": None, "full_name": None},
            "status": None,
            "last_used_at": "datetime",
            "commit_message": None,
            "datapoints_count": "integer",
            "datapoints": ("list", {0: {"id": None}}),
        },
        "evaluatees": (
            "list",
            {
                0: {
                    "version": {
                        "path": None,
                        "id": None,
                        "name": None,
                        "version_id": None,
                        "created_at": "datetime",
                        "updated_at": "datetime",
                        "status": None,
                        "last_used_at": "datetime",
                        "model": None,
                        "version_logs_count": "integer",
                        "total_logs_count": "integer",
                        "inputs": ("list", {0: {"name": None}}),
                    },
                    "batch_id": None,
                    "orchestrated": None,
                }
            },
        ),
        "evaluators": (
            "list",
            {
                0: {
                    "version": {
                        "path": None,
                        "id": None,
                        "name": None,
                        "version_id": None,
                        "created_at": "datetime",
                        "updated_at": "datetime",
                        "status": None,
                        "last_used_at": "datetime",
                        "spec": {"arguments_type": None, "return_type": None},
                        "version_logs_count": "integer",
                        "total_logs_count": "integer",
                        "inputs": ("list", {0: {"name": None}}),
                    },
                    "orchestrated": None,
                }
            },
        ),
        "status": None,
        "created_at": "datetime",
        "created_by": {"id": None, "email_address": None, "full_name": None},
        "updated_at": "datetime",
    }
    response = client.evaluations.update(
        id="id",
        dataset=EvaluationsDatasetRequest(version_id="version_id"),
        evaluatees=[EvaluateeRequest(version_id="version_id")],
        evaluators=[EvaluationsRequest(version_id="version_id")],
    )
    validate_response(response, expected_response, expected_types)

    async_response = await async_client.evaluations.update(
        id="id",
        dataset=EvaluationsDatasetRequest(version_id="version_id"),
        evaluatees=[EvaluateeRequest(version_id="version_id")],
        evaluators=[EvaluationsRequest(version_id="version_id")],
    )
    validate_response(async_response, expected_response, expected_types)


async def test_update_status(client: Humanloop, async_client: AsyncHumanloop) -> None:
    expected_response: typing.Any = {
        "id": "id",
        "dataset": {
            "path": "path",
            "id": "id",
            "name": "name",
            "version_id": "version_id",
            "type": "dataset",
            "environments": [{"id": "id", "created_at": "2024-01-15T09:30:00Z", "name": "name", "tag": "default"}],
            "created_at": "2024-01-15T09:30:00Z",
            "updated_at": "2024-01-15T09:30:00Z",
            "created_by": {"id": "id", "email_address": "email_address", "full_name": "full_name"},
            "status": "uncommitted",
            "last_used_at": "2024-01-15T09:30:00Z",
            "commit_message": "commit_message",
            "datapoints_count": 1,
            "datapoints": [{"id": "id"}],
        },
        "evaluatees": [
            {
                "version": {
                    "path": "path",
                    "id": "id",
                    "name": "name",
                    "version_id": "version_id",
                    "created_at": "2024-01-15T09:30:00Z",
                    "updated_at": "2024-01-15T09:30:00Z",
                    "status": "uncommitted",
                    "last_used_at": "2024-01-15T09:30:00Z",
                    "model": "model",
                    "version_logs_count": 1,
                    "total_logs_count": 1,
                    "inputs": [{"name": "name"}],
                },
                "batch_id": "batch_id",
                "orchestrated": True,
            }
        ],
        "evaluators": [
            {
                "version": {
                    "path": "path",
                    "id": "id",
                    "name": "name",
                    "version_id": "version_id",
                    "created_at": "2024-01-15T09:30:00Z",
                    "updated_at": "2024-01-15T09:30:00Z",
                    "status": "uncommitted",
                    "last_used_at": "2024-01-15T09:30:00Z",
                    "spec": {"arguments_type": "target_free", "return_type": "boolean"},
                    "version_logs_count": 1,
                    "total_logs_count": 1,
                    "inputs": [{"name": "name"}],
                },
                "orchestrated": True,
            }
        ],
        "status": "pending",
        "created_at": "2024-01-15T09:30:00Z",
        "created_by": {"id": "id", "email_address": "email_address", "full_name": "full_name"},
        "updated_at": "2024-01-15T09:30:00Z",
    }
    expected_types: typing.Any = {
        "id": None,
        "dataset": {
            "path": None,
            "id": None,
            "name": None,
            "version_id": None,
            "type": None,
            "environments": ("list", {0: {"id": None, "created_at": "datetime", "name": None, "tag": None}}),
            "created_at": "datetime",
            "updated_at": "datetime",
            "created_by": {"id": None, "email_address": None, "full_name": None},
            "status": None,
            "last_used_at": "datetime",
            "commit_message": None,
            "datapoints_count": "integer",
            "datapoints": ("list", {0: {"id": None}}),
        },
        "evaluatees": (
            "list",
            {
                0: {
                    "version": {
                        "path": None,
                        "id": None,
                        "name": None,
                        "version_id": None,
                        "created_at": "datetime",
                        "updated_at": "datetime",
                        "status": None,
                        "last_used_at": "datetime",
                        "model": None,
                        "version_logs_count": "integer",
                        "total_logs_count": "integer",
                        "inputs": ("list", {0: {"name": None}}),
                    },
                    "batch_id": None,
                    "orchestrated": None,
                }
            },
        ),
        "evaluators": (
            "list",
            {
                0: {
                    "version": {
                        "path": None,
                        "id": None,
                        "name": None,
                        "version_id": None,
                        "created_at": "datetime",
                        "updated_at": "datetime",
                        "status": None,
                        "last_used_at": "datetime",
                        "spec": {"arguments_type": None, "return_type": None},
                        "version_logs_count": "integer",
                        "total_logs_count": "integer",
                        "inputs": ("list", {0: {"name": None}}),
                    },
                    "orchestrated": None,
                }
            },
        ),
        "status": None,
        "created_at": "datetime",
        "created_by": {"id": None, "email_address": None, "full_name": None},
        "updated_at": "datetime",
    }
    response = client.evaluations.update_status(id="id", status="pending")
    validate_response(response, expected_response, expected_types)

    async_response = await async_client.evaluations.update_status(id="id", status="pending")
    validate_response(async_response, expected_response, expected_types)


async def test_get_stats(client: Humanloop, async_client: AsyncHumanloop) -> None:
    expected_response: typing.Any = {
        "overall_stats": {"num_datapoints": 1, "total_logs": 1, "total_evaluator_logs": 1},
        "version_stats": [
            {
                "version_id": "version_id",
                "num_logs": 1,
                "evaluator_version_stats": [
                    {
                        "evaluator_version_id": "evaluator_version_id",
                        "total_logs": 1,
                        "num_judgments": 1,
                        "num_nulls": 1,
                        "num_errors": 1,
                        "mean": 0,
                        "std": 1,
                        "percentiles": {"0": -2.5, "25": -0.6745, "50": 0, "75": 0.6745, "100": 2.5},
                    }
                ],
            }
        ],
    }
    expected_types: typing.Any = {
        "overall_stats": {"num_datapoints": "integer", "total_logs": "integer", "total_evaluator_logs": "integer"},
        "version_stats": (
            "list",
            {
                0: {
                    "version_id": None,
                    "num_logs": "integer",
                    "evaluator_version_stats": (
                        "list",
                        {
                            0: {
                                "evaluator_version_id": None,
                                "total_logs": "integer",
                                "num_judgments": "integer",
                                "num_nulls": "integer",
                                "num_errors": "integer",
                                "mean": None,
                                "std": None,
                                "percentiles": (
                                    "dict",
                                    {
                                        0: (None, None),
                                        1: (None, None),
                                        2: (None, None),
                                        3: (None, None),
                                        4: (None, None),
                                    },
                                ),
                            }
                        },
                    ),
                }
            },
        ),
    }
    response = client.evaluations.get_stats(id="id")
    validate_response(response, expected_response, expected_types)

    async_response = await async_client.evaluations.get_stats(id="id")
    validate_response(async_response, expected_response, expected_types)


async def test_get_logs(client: Humanloop, async_client: AsyncHumanloop) -> None:
    expected_response: typing.Any = {
        "records": [
            {
                "evaluated_version": {
                    "path": "path",
                    "id": "id",
                    "name": "name",
                    "version_id": "version_id",
                    "created_at": "2024-01-15T09:30:00Z",
                    "updated_at": "2024-01-15T09:30:00Z",
                    "status": "uncommitted",
                    "last_used_at": "2024-01-15T09:30:00Z",
                    "model": "model",
                    "version_logs_count": 1,
                    "total_logs_count": 1,
                    "inputs": [{"name": "name"}],
                },
                "datapoint": {"id": "id"},
                "log": {
                    "id": "id",
                    "config": {"id": "id", "type": "model", "model": "model"},
                    "evaluation_results": [
                        {
                            "id": "id",
                            "evaluator_id": "evaluator_id",
                            "evaluator_version_id": "evaluator_version_id",
                            "log_id": "log_id",
                            "updated_at": "2024-01-15T09:30:00Z",
                            "created_at": "2024-01-15T09:30:00Z",
                        }
                    ],
                    "observability_status": "pending",
                    "updated_at": "2024-01-15T09:30:00Z",
                },
                "evaluator_logs": [
                    {
                        "id": "id",
                        "config": {"id": "id", "type": "model", "model": "model"},
                        "evaluation_results": [
                            {
                                "id": "id",
                                "evaluator_id": "evaluator_id",
                                "evaluator_version_id": "evaluator_version_id",
                                "log_id": "log_id",
                                "updated_at": "2024-01-15T09:30:00Z",
                                "created_at": "2024-01-15T09:30:00Z",
                            }
                        ],
                        "observability_status": "pending",
                        "updated_at": "2024-01-15T09:30:00Z",
                    }
                ],
            }
        ],
        "page": 1,
        "size": 1,
        "total": 1,
    }
    expected_types: typing.Any = {
        "records": (
            "list",
            {
                0: {
                    "evaluated_version": {
                        "path": None,
                        "id": None,
                        "name": None,
                        "version_id": None,
                        "created_at": "datetime",
                        "updated_at": "datetime",
                        "status": None,
                        "last_used_at": "datetime",
                        "model": None,
                        "version_logs_count": "integer",
                        "total_logs_count": "integer",
                        "inputs": ("list", {0: {"name": None}}),
                    },
                    "datapoint": {"id": None},
                    "log": {
                        "id": None,
                        "config": {"id": None, "type": None, "model": None},
                        "evaluation_results": (
                            "list",
                            {
                                0: {
                                    "id": None,
                                    "evaluator_id": None,
                                    "evaluator_version_id": None,
                                    "log_id": None,
                                    "updated_at": "datetime",
                                    "created_at": "datetime",
                                }
                            },
                        ),
                        "observability_status": None,
                        "updated_at": "datetime",
                    },
                    "evaluator_logs": (
                        "list",
                        {
                            0: {
                                "id": None,
                                "config": {"id": None, "type": None, "model": None},
                                "evaluation_results": (
                                    "list",
                                    {
                                        0: {
                                            "id": None,
                                            "evaluator_id": None,
                                            "evaluator_version_id": None,
                                            "log_id": None,
                                            "updated_at": "datetime",
                                            "created_at": "datetime",
                                        }
                                    },
                                ),
                                "observability_status": None,
                                "updated_at": "datetime",
                            }
                        },
                    ),
                }
            },
        ),
        "page": "integer",
        "size": "integer",
        "total": "integer",
    }
    response = client.evaluations.get_logs(id="id")
    validate_response(response, expected_response, expected_types)

    async_response = await async_client.evaluations.get_logs(id="id")
    validate_response(async_response, expected_response, expected_types)
